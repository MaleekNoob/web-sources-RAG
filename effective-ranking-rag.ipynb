{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import logging\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from rank_bm25 import BM25Okapi\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key AIzaSyCAV73EKedKhVm3Vslz389wY6_OB1z2aw0 csid: 74a9c6ca4ecd7403c\n"
     ]
    }
   ],
   "source": [
    "# Your API key and Programmable Search Engine ID\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_CUSTOM_SEARCH_KEY')\n",
    "SEARCH_ENGINE_ID = os.getenv('CUSTOM_SEARCH_ENGINE_ID')\n",
    "\n",
    "print('key', GOOGLE_API_KEY, 'csid:', SEARCH_ENGINE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Google Generative AI\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GOOGLE_GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 23:30:39,390 - INFO - Use pytorch device_name: cpu\n",
      "2025-03-26 23:30:39,391 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract YouTube Video ID & Transcript\n",
    "def extract_video_id(url):\n",
    "    match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_transcript(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        text = \" \".join(entry['text'] for entry in transcript)\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fetch Web Search Results\n",
    "def google_search(query, num_results=5):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'key': GOOGLE_API_KEY,\n",
    "        'cx': SEARCH_ENGINE_ID,\n",
    "        'num': num_results\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an error for HTTP issues\n",
    "        results = response.json()\n",
    "        snippets = [item['snippet'] for item in results.get(\"items\", [])]\n",
    "        logging.info(\"Web search results fetched successfully.\")\n",
    "        return snippets\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching search results: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. BM25-Based Ranking\n",
    "def rank_snippets(query, snippets):\n",
    "    if not snippets:\n",
    "        return []  # Avoid ZeroDivisionError\n",
    "    tokenized_corpus = [snippet.split() for snippet in snippets]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    scores = bm25.get_scores(query.split())\n",
    "    ranked_snippets = sorted(zip(snippets, scores), key=lambda x: x[1], reverse=True)\n",
    "    logging.info(\"BM25 ranking completed.\")\n",
    "    return [snippet for snippet, _ in ranked_snippets[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LLM-Based Filtering\n",
    "\n",
    "def rank_relevance(query, snippets):\n",
    "    if not snippets:\n",
    "        return []\n",
    "    scored_snippets = []\n",
    "    for snippet in snippets:\n",
    "        prompt = f\"On a scale of 1-10, how relevant is this snippet to '{query}'? Reply with ONLY the number:\\n\\n{snippet}\"\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            raw_score = response.text.strip()\n",
    "            match = re.search(r'\\b([1-9]|10)\\b', raw_score)\n",
    "            if match:\n",
    "                score = int(match.group(1))\n",
    "                scored_snippets.append((snippet, score))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in LLM-based ranking: {e}\")\n",
    "            scored_snippets.append((snippet, 0))\n",
    "    logging.info(\"LLM-based relevance filtering completed.\")\n",
    "    return sorted(scored_snippets, key=lambda x: x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Embedding-Based Re-ranking\n",
    "def embedding_rerank(query, snippets):\n",
    "    if not snippets:\n",
    "        return []\n",
    "    snippets = [snippet if isinstance(snippet, str) else snippet[0] for snippet in snippets]  # Ensure pure strings\n",
    "\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "    snippet_embeddings = embedding_model.encode(snippets, convert_to_tensor=True)\n",
    "\n",
    "    if snippet_embeddings.shape[0] == 0:\n",
    "        logging.warning(\"No valid embeddings found for snippets.\")\n",
    "        return []  # Avoid empty matrix multiplication error\n",
    "    \n",
    "    similarities = util.pytorch_cos_sim(query_embedding, snippet_embeddings)[0]\n",
    "    ranked_snippets = sorted(zip(snippets, similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    logging.info(\"Embedding-based ranking completed.\")\n",
    "    return [snippet for snippet, _ in ranked_snippets[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Generate Final Response\n",
    "def generate_response(video_transcript, web_snippets, query):\n",
    "    combined_content = f\"Relevant Video Transcript:\\n{video_transcript[:1000]}\\n\\nRelevant Web Snippets:\\n\" + \"\\n\".join(web_snippets)\n",
    "    prompt = f\"Answer the following query using the provided content:\\nQuery: {query}\\n\\n{combined_content}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Example Usage\n",
    "url = \"https://www.youtube.com/watch?v=UeTOW5exFmE\"\n",
    "query = \"FIFA World Cup 2026 latest updates\"\n",
    "\n",
    "video_id = extract_video_id(url)\n",
    "video_transcript = get_transcript(video_id)\n",
    "web_results = google_search(query)\n",
    "bm25_ranked = rank_snippets(query, web_results)\n",
    "llm_filtered = rank_relevance(query, bm25_ranked)\n",
    "embedding_ranked = embedding_rerank(query, llm_filtered)\n",
    "final_response = generate_response(video_transcript, embedding_ranked, query)\n",
    "\n",
    "print(\"\\nðŸš€ Final AI Response:\\n\", final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
